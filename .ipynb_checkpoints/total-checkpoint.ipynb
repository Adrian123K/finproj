{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### # dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "class CPDataset(data.Dataset):\n",
    "    \"\"\"Dataset for CP-VTON+.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(CPDataset, self).__init__()\n",
    "        # base setting\n",
    "        self.opt = opt\n",
    "        self.root = opt.dataroot\n",
    "        self.datamode = opt.datamode  # train or test or self-defined\n",
    "        self.stage = opt.stage  # GMM or TOM\n",
    "        self.data_list = opt.data_list\n",
    "        self.fine_height = opt.fine_height\n",
    "        self.fine_width = opt.fine_width\n",
    "        self.radius = opt.radius\n",
    "        self.data_path = osp.join(opt.dataroot, opt.datamode)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        # load data list\n",
    "        im_names = []\n",
    "        c_names = []\n",
    "        with open(osp.join(opt.dataroot, opt.data_list), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                im_name, c_name = line.strip().split()\n",
    "                im_names.append(im_name)\n",
    "                c_names.append(c_name)\n",
    "\n",
    "        self.im_names = im_names\n",
    "        self.c_names = c_names\n",
    "\n",
    "    def name(self):\n",
    "        return \"CPDataset\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        c_name = self.c_names[index]\n",
    "        im_name = self.im_names[index]\n",
    "        if self.stage == 'GMM':\n",
    "            c = Image.open(osp.join(self.data_path, 'cloth', c_name))\n",
    "            cm = Image.open(osp.join(self.data_path, 'cloth-mask', c_name)).convert('L')\n",
    "        else:\n",
    "            c = Image.open(osp.join(self.data_path, 'warp-cloth', im_name))    # c_name, if that is used when saved\n",
    "            cm = Image.open(osp.join(self.data_path, 'warp-mask', im_name)).convert('L')    # c_name, if that is used when saved\n",
    "\n",
    "        c = self.transform(c)  # [-1,1]\n",
    "        cm_array = np.array(cm)\n",
    "        cm_array = (cm_array >= 128).astype(np.float32)\n",
    "        cm = torch.from_numpy(cm_array)  # [0,1]\n",
    "        cm.unsqueeze_(0)\n",
    "\n",
    "        # person image\n",
    "        im = Image.open(osp.join(self.data_path, 'image', im_name))\n",
    "        im = self.transform(im)  # [-1,1]\n",
    "\n",
    "        \"\"\"\n",
    "        LIP labels\n",
    "        \n",
    "        [(0, 0, 0),    # 0=Background\n",
    "         (128, 0, 0),  # 1=Hat\n",
    "         (255, 0, 0),  # 2=Hair\n",
    "         (0, 85, 0),   # 3=Glove\n",
    "         (170, 0, 51),  # 4=SunGlasses\n",
    "         (255, 85, 0),  # 5=UpperClothes\n",
    "         (0, 0, 85),     # 6=Dress\n",
    "         (0, 119, 221),  # 7=Coat\n",
    "         (85, 85, 0),    # 8=Socks\n",
    "         (0, 85, 85),    # 9=Pants\n",
    "         (85, 51, 0),    # 10=Jumpsuits\n",
    "         (52, 86, 128),  # 11=Scarf\n",
    "         (0, 128, 0),    # 12=Skirt\n",
    "         (0, 0, 255),    # 13=Face\n",
    "         (51, 170, 221),  # 14=LeftArm\n",
    "         (0, 255, 255),   # 15=RightArm\n",
    "         (85, 255, 170),  # 16=LeftLeg\n",
    "         (170, 255, 85),  # 17=RightLeg\n",
    "         (255, 255, 0),   # 18=LeftShoe\n",
    "         (255, 170, 0)    # 19=RightShoe\n",
    "         (170, 170, 50)   # 20=Skin/Neck/Chest (Newly added after running dataset_neck_skin_correction.py)\n",
    "         ]\n",
    "         \"\"\"\n",
    "\n",
    "        # load parsing image\n",
    "        parse_name = im_name.replace('.jpg', '.png')\n",
    "        im_parse = Image.open(\n",
    "            # osp.join(self.data_path, 'image-parse', parse_name)).convert('L')\n",
    "            osp.join(self.data_path, 'image-parse-new', parse_name)).convert('L')   # updated new segmentation\n",
    "        parse_array = np.array(im_parse)\n",
    "        im_mask = Image.open(\n",
    "            osp.join(self.data_path, 'image-mask', parse_name)).convert('L')\n",
    "        mask_array = np.array(im_mask)\n",
    "\n",
    "        # parse_shape = (parse_array > 0).astype(np.float32)  # CP-VTON body shape\n",
    "        # Get shape from body mask (CP-VTON+)\n",
    "        parse_shape = (mask_array > 0).astype(np.float32)\n",
    "\n",
    "        if self.stage == 'GMM':\n",
    "            parse_head = (parse_array == 1).astype(np.float32) + \\\n",
    "                (parse_array == 4).astype(np.float32) + \\\n",
    "                (parse_array == 13).astype(\n",
    "                    np.float32)  # CP-VTON+ GMM input (reserved regions)\n",
    "        else:\n",
    "            parse_head = (parse_array == 1).astype(np.float32) + \\\n",
    "                (parse_array == 2).astype(np.float32) + \\\n",
    "                (parse_array == 4).astype(np.float32) + \\\n",
    "                (parse_array == 9).astype(np.float32) + \\\n",
    "                (parse_array == 12).astype(np.float32) + \\\n",
    "                (parse_array == 13).astype(np.float32) + \\\n",
    "                (parse_array == 16).astype(np.float32) + \\\n",
    "                (parse_array == 17).astype(\n",
    "                np.float32)  # CP-VTON+ TOM input (reserved regions)\n",
    "\n",
    "        parse_cloth = (parse_array == 5).astype(np.float32) + \\\n",
    "            (parse_array == 6).astype(np.float32) + \\\n",
    "            (parse_array == 7).astype(np.float32)    # upper-clothes labels\n",
    "\n",
    "        # shape downsample\n",
    "        parse_shape_ori = Image.fromarray((parse_shape*255).astype(np.uint8))\n",
    "        parse_shape = parse_shape_ori.resize(\n",
    "            (self.fine_width//16, self.fine_height//16), Image.BILINEAR)\n",
    "        parse_shape = parse_shape.resize(\n",
    "            (self.fine_width, self.fine_height), Image.BILINEAR)\n",
    "        parse_shape_ori = parse_shape_ori.resize(\n",
    "            (self.fine_width, self.fine_height), Image.BILINEAR)\n",
    "        shape_ori = self.transform(parse_shape_ori)  # [-1,1]\n",
    "        shape = self.transform(parse_shape)  # [-1,1]\n",
    "        phead = torch.from_numpy(parse_head)  # [0,1]\n",
    "        # phand = torch.from_numpy(parse_hand)  # [0,1]\n",
    "        pcm = torch.from_numpy(parse_cloth)  # [0,1]\n",
    "\n",
    "        # upper cloth\n",
    "        im_c = im * pcm + (1 - pcm)  # [-1,1], fill 1 for other parts\n",
    "        im_h = im * phead - (1 - phead)  # [-1,1], fill 0 for other parts\n",
    "\n",
    "        # load pose points\n",
    "        pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
    "        with open(osp.join(self.data_path, 'pose', pose_name), 'r') as f:\n",
    "            pose_label = json.load(f)\n",
    "            pose_data = pose_label['people'][0]['pose_keypoints']\n",
    "            pose_data = np.array(pose_data)\n",
    "            pose_data = pose_data.reshape((-1, 3))\n",
    "\n",
    "        point_num = pose_data.shape[0]\n",
    "        pose_map = torch.zeros(point_num, self.fine_height, self.fine_width)\n",
    "        r = self.radius\n",
    "        im_pose = Image.new('L', (self.fine_width, self.fine_height))\n",
    "        pose_draw = ImageDraw.Draw(im_pose)\n",
    "        for i in range(point_num):\n",
    "            one_map = Image.new('L', (self.fine_width, self.fine_height))\n",
    "            draw = ImageDraw.Draw(one_map)\n",
    "            pointx = pose_data[i, 0]\n",
    "            pointy = pose_data[i, 1]\n",
    "            if pointx > 1 and pointy > 1:\n",
    "                draw.rectangle((pointx-r, pointy-r, pointx +\n",
    "                                r, pointy+r), 'white', 'white')\n",
    "                pose_draw.rectangle(\n",
    "                    (pointx-r, pointy-r, pointx+r, pointy+r), 'white', 'white')\n",
    "            one_map = self.transform(one_map)\n",
    "            pose_map[i] = one_map[0]\n",
    "\n",
    "        # just for visualization\n",
    "        im_pose = self.transform(im_pose)\n",
    "\n",
    "        # cloth-agnostic representation\n",
    "        agnostic = torch.cat([shape, im_h, pose_map], 0)\n",
    "\n",
    "        if self.stage == 'GMM':\n",
    "            im_g = Image.open('grid.png')\n",
    "            im_g = self.transform(im_g)\n",
    "        else:\n",
    "            im_g = ''\n",
    "\n",
    "        pcm.unsqueeze_(0)  # CP-VTON+\n",
    "\n",
    "        result = {\n",
    "            'c_name':   c_name,     # for visualization\n",
    "            'im_name':  im_name,    # for visualization or ground truth\n",
    "            'cloth':    c,          # for input\n",
    "            'cloth_mask':     cm,   # for input\n",
    "            'image':    im,         # for visualization\n",
    "            'agnostic': agnostic,   # for input\n",
    "            'parse_cloth': im_c,    # for ground truth\n",
    "            'shape': shape,         # for visualization\n",
    "            'head': im_h,           # for visualization\n",
    "            'pose_image': im_pose,  # for visualization\n",
    "            'grid_image': im_g,     # for visualization\n",
    "            'parse_cloth_mask': pcm,     # for CP-VTON+, TOM input\n",
    "            'shape_ori': shape_ori,     # original body shape without resize\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_names)\n",
    "\n",
    "\n",
    "class CPDataLoader(object):\n",
    "    def __init__(self, opt, dataset):\n",
    "        super(CPDataLoader, self).__init__()\n",
    "\n",
    "        if opt.shuffle:\n",
    "            train_sampler = torch.utils.data.sampler.RandomSampler(dataset)\n",
    "        else:\n",
    "            train_sampler = None\n",
    "\n",
    "        self.data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=opt.batch_size, shuffle=(\n",
    "                train_sampler is None),\n",
    "            num_workers=opt.workers, pin_memory=True, sampler=train_sampler)\n",
    "        self.dataset = dataset\n",
    "        self.data_iter = self.data_loader.__iter__()\n",
    "\n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            batch = self.data_iter.__next__()\n",
    "        except StopIteration:\n",
    "            self.data_iter = self.data_loader.__iter__()\n",
    "            batch = self.data_iter.__next__()\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Check the dataset for geometric matching module!\")\n",
    "\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dataroot\", default=\"data\")\n",
    "    parser.add_argument(\"--datamode\", default=\"train\")\n",
    "    parser.add_argument(\"--stage\", default=\"GMM\")\n",
    "    parser.add_argument(\"--data_list\", default=\"train_pairs.txt\")\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "    parser.add_argument(\"--radius\", type=int, default=3)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true',\n",
    "                        help='shuffle input data')\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=4)\n",
    "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    dataset = CPDataset(opt)\n",
    "    data_loader = CPDataLoader(opt, dataset)\n",
    "\n",
    "    print('Size of the dataset: %05d, dataloader: %04d'\n",
    "          % (len(dataset), len(data_loader.data_loader)))\n",
    "    first_item = dataset.__getitem__(0)\n",
    "    first_batch = data_loader.next_batch()\n",
    "\n",
    "    from IPython import embed\n",
    "    embed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # body_binary_masking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make updated body shape from updated segmentation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "(cv_major, _, _) = cv2.__version__.split(\".\")\n",
    "if cv_major != '4' and cv_major != '3':\n",
    "    print('doesnot support opencv version')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# @TODO this is too simple and pixel based algorithm\n",
    "def body_detection(image, seg_mask):\n",
    "    # binary thresholding by blue ?\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([0, 0, 120])\n",
    "    upper_blue = np.array([180, 38, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # binary threshold by green ?\n",
    "    b, g, r = cv2.split(result)\n",
    "    filter = g.copy()\n",
    "    ret, mask = cv2.threshold(filter, 10, 255, 1)\n",
    "\n",
    "    # at least original segmentation is FG\n",
    "    mask[seg_mask] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def make_body_mask(data_dir, seg_dir, image_name, mask_name, save_dir=None):\n",
    "    print(image_name)\n",
    "\n",
    "    # define paths\n",
    "    img_pth = os.path.join(data_dir, image_name)\n",
    "    seg_pth = os.path.join(seg_dir, mask_name)\n",
    "\n",
    "    mask_path = None\n",
    "    if save_dir is not None:\n",
    "        mask_path = os.path.join(save_dir, mask_name)\n",
    "\n",
    "    # Load images\n",
    "    img = cv2.imread(img_pth)\n",
    "    # segm = Image.open(seg_pth)\n",
    "    # the png file should be 1-ch but it is 3 ch ^^;\n",
    "    gray = cv2.imread(seg_pth, cv2.IMREAD_GRAYSCALE)\n",
    "    _, seg_mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    body_mask = body_detection(img, seg_mask)\n",
    "    body_mask = body_mask + seg_mask\n",
    "    body_mask[seg_mask] = 1\n",
    "    cv2.imwrite(mask_path, body_mask)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # define paths\n",
    "\n",
    "    # root_dir = \"data/viton_resize\"\n",
    "    root_dir = \"data/\"\n",
    "    mask_folder = \"image-mask\"\n",
    "    seg_folder = \"image-parse-new\"\n",
    "\n",
    "    # data_mode = \"train\"\n",
    "    data_mode = \"test\"\n",
    "    image_folder = \"image\"\n",
    "\n",
    "    image_dir = os.path.join(os.path.join(root_dir, data_mode), image_folder)\n",
    "    seg_dir = os.path.join(os.path.join(root_dir, data_mode), seg_folder)\n",
    "\n",
    "    image_list = os.listdir(image_dir)\n",
    "    seg_list = os.listdir(seg_dir)\n",
    "\n",
    "    mask_dir = os.path.join(os.path.join(root_dir, data_mode), mask_folder)\n",
    "    if not os.path.exists(mask_dir):\n",
    "        os.makedirs(mask_dir)\n",
    "\n",
    "    for each in zip(image_list, seg_list):\n",
    "        make_body_mask(image_dir, seg_dir, each[0], each[1], mask_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # data_download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "\n",
    "def download(url, filename, cookies=None):\n",
    "    with open(filename, 'wb') as f:\n",
    "        response = requests.get(url, stream=True, cookies=cookies)\n",
    "        total = response.headers.get('content-length')\n",
    "\n",
    "        if total is None:\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            downloaded = 0\n",
    "            total = int(total)\n",
    "            for data in response.iter_content(chunk_size=max(int(total/1000), 1024*1024)):\n",
    "                downloaded += len(data)\n",
    "                f.write(data)\n",
    "                completed = int(50*downloaded/total)\n",
    "                sys.stdout.write('\\r[{}{}]'.format(\n",
    "                    'â–ˆ' * completed, '.' * (50-completed)))\n",
    "                sys.stdout.flush()\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "\n",
    "drive_request = requests.get(\n",
    "    'https://drive.google.com/uc?export=download&confirm=CONFIRM&id=1MxCUvKxejnwWnoZ-KoCyMCXo3TLhRuTo')\n",
    "confirm_page = drive_request.text\n",
    "confirmation_code = re.findall('confirm=(.{4})', confirm_page)[0]\n",
    "\n",
    "print('[*] Downloading data...')\n",
    "download('https://drive.google.com/uc?export=download&confirm=CONFIRM&id=1MxCUvKxejnwWnoZ-KoCyMCXo3TLhRuTo'.replace(\n",
    "    'CONFIRM', confirmation_code), 'data/viton_resize.tar.gz', cookies=drive_request.cookies)\n",
    "\n",
    "tarfile.open(\"data/viton_resize.tar.gz\").extractall(path='data/')\n",
    "\n",
    "shutil.move('data/viton_resize/test/', 'data/test/')\n",
    "shutil.move('data/viton_resize/train/', 'data/train/')\n",
    "\n",
    "os.rmdir('data/viton_resize/')\n",
    "os.remove('data/viton_resize.tar.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # dataset_neck_skin_correction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make updated body segmentation with new neck/skin label\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "N_CLASSES = 21\n",
    "fine_width = 192\n",
    "fine_height = 256\n",
    "\n",
    "# colour map for LIP dataset (plus extra)\n",
    "label_colours = [(0, 0, 0),  # 0=Background\n",
    "                 (128, 0, 0),  # 1=Hat\n",
    "                 (255, 0, 0),  # 2=Hair\n",
    "                 (0, 85, 0),   # 3=Glove\n",
    "                 (170, 0, 51),  # 4=Sunglasses\n",
    "                 (255, 85, 0),  # 5=UpperClothes\n",
    "                 (0, 0, 85),  # 6=Dress\n",
    "                 (0, 119, 221),  # 7=Coat\n",
    "                 (85, 85, 0),  # 8=Socks\n",
    "                 (0, 85, 85),  # 9=Pants\n",
    "                 (85, 51, 0),  # 10=Jumpsuits\n",
    "                 (52, 86, 128),  # 11=Scarf\n",
    "                 (0, 128, 0),  # 12=Skirt\n",
    "                 (0, 0, 255),  # 13=Face\n",
    "                 (51, 170, 221),  # 14=LeftArm\n",
    "                 (0, 255, 255),  # 15=RightArm\n",
    "                 (85, 255, 170),  # 16=LeftLeg\n",
    "                 (170, 255, 85),  # 17=RightLeg\n",
    "                 (255, 255, 0),  # 18=LeftShoe\n",
    "                 (255, 170, 0),  # 19=RightShoe\n",
    "                 (189, 183, 107)  # 20=Neck    # new added\n",
    "                 ]\n",
    "\n",
    "(cv_major, _, _) = cv2.__version__.split(\".\")\n",
    "if cv_major != '4' and cv_major != '3':\n",
    "    print('doesnot support opencv version')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "def decode_labels(mask):\n",
    "    \"\"\"Decode segmentation masks.\n",
    "    Args:\n",
    "      mask: result of inference after taking argmax.\n",
    "      num_images: number of images to decode from the batch.\n",
    "      num_classes: num of classes\n",
    "    Returns:\n",
    "      A RGB image of the same size as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.expand_dims(mask, axis=2)\n",
    "    h, w, c = mask.shape\n",
    "\n",
    "    outputs = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    par_img = Image.new('RGB', (w, h))\n",
    "    pixels = par_img.load()\n",
    "    for j_, j in enumerate(mask[:, :, 0]):\n",
    "        for k_, k in enumerate(j):\n",
    "            if k < N_CLASSES:\n",
    "                pixels[k_, j_] = label_colours[k]\n",
    "    outputs = np.array(par_img)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# @TODO this is too simple and pixel based algorithm\n",
    "def body_detection(image, seg_mask):\n",
    "    # binary thresholding by blue ?\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([0, 0, 120])\n",
    "    upper_blue = np.array([180, 38, 255])\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # binary threshold by green ?\n",
    "    b, g, r = cv2.split(result)\n",
    "    filter = g.copy()\n",
    "    ret, mask = cv2.threshold(filter, 10, 255, 1)\n",
    "\n",
    "    # at least original segmentation is FG\n",
    "    mask[seg_mask] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def shape_from_contour(img, contour):\n",
    "    dummy_mask = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "    dummy_mask = cv2.drawContours(\n",
    "        dummy_mask, [contour], 0, (1, 0, 0), thickness=cv2.FILLED)\n",
    "    x, y = np.where(dummy_mask[:, :, 0] == 1)\n",
    "    inside_points = np.stack((x, y), axis=-1)\n",
    "    return inside_points\n",
    "\n",
    "\n",
    "#\n",
    "# relabel the segmented mask with neck\n",
    "# dir_dir  : input image file dir  path\n",
    "# image_name : image file name\n",
    "# mask_dir : original mask dir path\n",
    "# mask_name : original mask image file\n",
    "# save_dir  : the re-labeled dir path (same name as mask_name)\n",
    "#\n",
    "#\n",
    "def update_image_segmentation(data_dir, mask_dir, image_name, mask_name, save_dir=None, save_vis=True):\n",
    "    print(image_name)\n",
    "\n",
    "    # define paths\n",
    "    img_pth = os.path.join(data_dir, image_name)\n",
    "    seg_pth = os.path.join(mask_dir, mask_name)\n",
    "\n",
    "    updated_seg_pth = None\n",
    "    updated_seg_vis_pth = None\n",
    "    if save_dir is not None:\n",
    "        updated_seg_pth = os.path.join(save_dir, mask_name)\n",
    "        if save_vis:\n",
    "            updated_seg_vis_pth = updated_seg_pth.replace(\"image-parse-new\", \"image-parse-new-vis\")\n",
    "            if not os.path.exists(updated_seg_vis_pth):\n",
    "                os.makedirs(updated_seg_vis_pth)\n",
    "\n",
    "    # Load image and make binary body mask\n",
    "    img = cv2.imread(img_pth)\n",
    "\n",
    "    # Load the segmentation in grayscale and make binary mask\n",
    "    segmentation = Image.open(seg_pth)\n",
    "\n",
    "    # the png file should be 1-ch but it is 3 ch ^^;\n",
    "    gray = cv2.imread(seg_pth, cv2.IMREAD_GRAYSCALE)\n",
    "    # print('shape of seg:', seg_pth, ':', gray.shape)\n",
    "    # _, seg_mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)  # why 10? bg is 0\n",
    "    _, seg_mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    body_mask = body_detection(img, seg_mask)\n",
    "\n",
    "    # Get the neck/skin region (plus extra mis-segmented)\n",
    "    upper_body = body_mask - seg_mask\n",
    "    upper_body[upper_body > 0] = 20\n",
    "    upper_body_vis = upper_body.copy()\n",
    "\n",
    "    # location info: @TODO by joint locations (neck should be between neck and hips vertically, between shoulder horizontally)\n",
    "    # print(upper_body.shape)\n",
    "    height, width = upper_body.shape\n",
    "    upper_body[height//2:, :] = 0\n",
    "    # noise reduction\n",
    "\n",
    "    # get contours\n",
    "    if cv_major == '4':\n",
    "        contours, hier = cv2.findContours(\n",
    "            upper_body, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    elif cv_major == '3':\n",
    "        _, contours, hier = cv2.findContours(\n",
    "            upper_body, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    neck = None\n",
    "\n",
    "    if len(contours) > 0:\n",
    "        # draw in blue the contours that were founded\n",
    "        cv2.drawContours(upper_body_vis, contours, -1, 255, 3)\n",
    "\n",
    "        # find the biggest area\n",
    "        c_neck = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        neck = shape_from_contour(img, c_neck)\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(c_neck)\n",
    "        # draw the book contour (in green)\n",
    "        cv2.rectangle(upper_body_vis, (x, y), (x + w, y + h), (170, 230, 0), 2)\n",
    "\n",
    "    # make neck region mask\n",
    "    neck_mask = np.zeros((fine_height, fine_width)).astype(np.int)\n",
    "    for each in neck:\n",
    "        neck_mask[each[0]][each[1]] = 20\n",
    "\n",
    "    # Add neck/skin to segmentation\n",
    "    result = segmentation + neck_mask\n",
    "\n",
    "    # handle overlapped pixels\n",
    "    for i in range(1, 20):\n",
    "        result[result == 20 + i] = i\n",
    "\n",
    "    # save new segmentation\n",
    "    if updated_seg_pth is not None:\n",
    "        cv2.imwrite(updated_seg_pth, result)\n",
    "        if save_vis:\n",
    "            msk = decode_labels(result)\n",
    "            parsing_im = Image.fromarray(msk)\n",
    "            parsing_im.save('{}/{}_vis.png'.format(updated_seg_vis_pth, mask_name[:-4]))\n",
    "    else:  # display for checking\n",
    "\n",
    "        plt.suptitle(image_name)\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.title(\"input\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:, :, ::-1])\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.title(\"body silhouette\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(body_mask)\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.title(\"orig. mask\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(segmentation)\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.title(\"relabeled\")\n",
    "        plt.axis('off')\n",
    "        msk = decode_labels(result)         # ???\n",
    "        parsing_im = Image.fromarray(msk)   # ???\n",
    "        plt.imshow(parsing_im)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # define paths\n",
    "\n",
    "    root_dir = \"data/\"\n",
    "    updated_seg_folder = \"image-parse-new\"\n",
    "\n",
    "    # data_mode = \"train\"\n",
    "    data_mode = \"test\"\n",
    "    image_folder = \"image\"\n",
    "    seg_folder = \"image-parse\"\n",
    "\n",
    "    image_dir = os.path.join(os.path.join(root_dir, data_mode), image_folder)\n",
    "    seg_dir = os.path.join(os.path.join(root_dir, data_mode), seg_folder)\n",
    "    if updated_seg_folder is not None:\n",
    "        updated_seg_dir = os.path.join(os.path.join(\n",
    "            root_dir, data_mode), updated_seg_folder)\n",
    "        if not os.path.exists(updated_seg_dir):\n",
    "            os.makedirs(updated_seg_dir)\n",
    "    else:\n",
    "        updated_seg_dir = None\n",
    "\n",
    "    image_list = os.listdir(image_dir)\n",
    "    masks_list = os.listdir(seg_dir)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(os.path.join(image_dir, '.ipynb_checkpoints'))\n",
    "        shutil.rmtree(os.path.join(seg_dir, '.ipynb_checkpoints'))\n",
    "    except:\n",
    "        print(\"Clean\")   \n",
    "    for each in zip(image_list, masks_list):\n",
    "        mask = each[0].replace(\"jpg\", \"png\")\n",
    "        update_image_segmentation(\n",
    "            image_dir, seg_dir, each[0], mask, updated_seg_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # networks.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_normal_(m.weight.data, gain=0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.xavier_normal_(m.weight.data, gain=0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal'):\n",
    "    print('initialization method [%s]' % init_type)\n",
    "    if init_type == 'normal':\n",
    "        net.apply(weights_init_normal)\n",
    "    elif init_type == 'xavier':\n",
    "        net.apply(weights_init_xavier)\n",
    "    elif init_type == 'kaiming':\n",
    "        net.apply(weights_init_kaiming)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [%s] is not implemented' % init_type)\n",
    "\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(self, input_nc, ngf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(FeatureExtraction, self).__init__()\n",
    "        downconv = nn.Conv2d(input_nc, ngf, kernel_size=4, stride=2, padding=1)\n",
    "        model = [downconv, nn.ReLU(True), norm_layer(ngf)]\n",
    "        for i in range(n_layers):\n",
    "            in_ngf = 2**i * ngf if 2**i * ngf < 512 else 512\n",
    "            out_ngf = 2**(i+1) * ngf if 2**i * ngf < 512 else 512\n",
    "            downconv = nn.Conv2d(\n",
    "                in_ngf, out_ngf, kernel_size=4, stride=2, padding=1)\n",
    "            model += [downconv, nn.ReLU(True)]\n",
    "            model += [norm_layer(out_ngf)]\n",
    "        model += [nn.Conv2d(512, 512, kernel_size=3,\n",
    "                            stride=1, padding=1), nn.ReLU(True)]\n",
    "        model += [norm_layer(512)]\n",
    "        model += [nn.Conv2d(512, 512, kernel_size=3,\n",
    "                            stride=1, padding=1), nn.ReLU(True)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "        init_weights(self.model, init_type='normal')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class FeatureL2Norm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureL2Norm, self).__init__()\n",
    "\n",
    "    def forward(self, feature):\n",
    "        epsilon = 1e-6\n",
    "        norm = torch.pow(torch.sum(torch.pow(feature, 2), 1) +\n",
    "                         epsilon, 0.5).unsqueeze(1).expand_as(feature)\n",
    "        return torch.div(feature, norm)\n",
    "\n",
    "\n",
    "class FeatureCorrelation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureCorrelation, self).__init__()\n",
    "\n",
    "    def forward(self, feature_A, feature_B):\n",
    "        b, c, h, w = feature_A.size()\n",
    "        # reshape features for matrix multiplication\n",
    "        feature_A = feature_A.transpose(2, 3).contiguous().view(b, c, h*w)\n",
    "        feature_B = feature_B.view(b, c, h*w).transpose(1, 2)\n",
    "        # perform matrix mult.\n",
    "        feature_mul = torch.bmm(feature_B, feature_A)\n",
    "        correlation_tensor = feature_mul.view(\n",
    "            b, h, w, h*w).transpose(2, 3).transpose(1, 2)\n",
    "        return correlation_tensor\n",
    "\n",
    "\n",
    "class FeatureRegression(nn.Module):\n",
    "    def __init__(self, input_nc=512, output_dim=6, use_cuda=True):\n",
    "        super(FeatureRegression, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.linear = nn.Linear(64 * 4 * 3, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        if use_cuda:\n",
    "            self.conv.cuda()\n",
    "            self.linear.cuda()\n",
    "            self.tanh.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = self.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AffineGridGen(nn.Module):\n",
    "    def __init__(self, out_h=256, out_w=192, out_ch=3):\n",
    "        super(AffineGridGen, self).__init__()\n",
    "        self.out_h = out_h\n",
    "        self.out_w = out_w\n",
    "        self.out_ch = out_ch\n",
    "\n",
    "    def forward(self, theta):\n",
    "        theta = theta.contiguous()\n",
    "        batch_size = theta.size()[0]\n",
    "        out_size = torch.Size(\n",
    "            (batch_size, self.out_ch, self.out_h, self.out_w))\n",
    "        return F.affine_grid(theta, out_size)\n",
    "\n",
    "\n",
    "class TpsGridGen(nn.Module):\n",
    "    def __init__(self, out_h=256, out_w=192, use_regular_grid=True, grid_size=3, reg_factor=0, use_cuda=True):\n",
    "        super(TpsGridGen, self).__init__()\n",
    "        self.out_h, self.out_w = out_h, out_w\n",
    "        self.reg_factor = reg_factor\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        # create grid in numpy\n",
    "        self.grid = np.zeros([self.out_h, self.out_w, 3], dtype=np.float32)\n",
    "        # sampling grid with dim-0 coords (Y)\n",
    "        self.grid_X, self.grid_Y = np.meshgrid(\n",
    "            np.linspace(-1, 1, out_w), np.linspace(-1, 1, out_h))\n",
    "        # grid_X,grid_Y: size [1,H,W,1,1]\n",
    "        self.grid_X = torch.FloatTensor(self.grid_X).unsqueeze(0).unsqueeze(3)\n",
    "        self.grid_Y = torch.FloatTensor(self.grid_Y).unsqueeze(0).unsqueeze(3)\n",
    "        if use_cuda:\n",
    "            self.grid_X = self.grid_X.cuda()\n",
    "            self.grid_Y = self.grid_Y.cuda()\n",
    "\n",
    "        # initialize regular grid for control points P_i\n",
    "        if use_regular_grid:\n",
    "            axis_coords = np.linspace(-1, 1, grid_size)\n",
    "            self.N = grid_size*grid_size\n",
    "            P_Y, P_X = np.meshgrid(axis_coords, axis_coords)\n",
    "            P_X = np.reshape(P_X, (-1, 1))  # size (N,1)\n",
    "            P_Y = np.reshape(P_Y, (-1, 1))  # size (N,1)\n",
    "            P_X = torch.FloatTensor(P_X)\n",
    "            P_Y = torch.FloatTensor(P_Y)\n",
    "            self.P_X_base = P_X.clone()\n",
    "            self.P_Y_base = P_Y.clone()\n",
    "            self.Li = self.compute_L_inverse(P_X, P_Y).unsqueeze(0)\n",
    "            self.P_X = P_X.unsqueeze(2).unsqueeze(\n",
    "                3).unsqueeze(4).transpose(0, 4)\n",
    "            self.P_Y = P_Y.unsqueeze(2).unsqueeze(\n",
    "                3).unsqueeze(4).transpose(0, 4)\n",
    "            if use_cuda:\n",
    "                self.P_X = self.P_X.cuda()\n",
    "                self.P_Y = self.P_Y.cuda()\n",
    "                self.P_X_base = self.P_X_base.cuda()\n",
    "                self.P_Y_base = self.P_Y_base.cuda()\n",
    "\n",
    "    def forward(self, theta):\n",
    "        warped_grid = self.apply_transformation(\n",
    "            theta, torch.cat((self.grid_X, self.grid_Y), 3))\n",
    "\n",
    "        return warped_grid\n",
    "\n",
    "    def compute_L_inverse(self, X, Y):\n",
    "        N = X.size()[0]  # num of points (along dim 0)\n",
    "        # construct matrix K\n",
    "        Xmat = X.expand(N, N)\n",
    "        Ymat = Y.expand(N, N)\n",
    "        P_dist_squared = torch.pow(\n",
    "            Xmat-Xmat.transpose(0, 1), 2)+torch.pow(Ymat-Ymat.transpose(0, 1), 2)\n",
    "        # make diagonal 1 to avoid NaN in log computation\n",
    "        P_dist_squared[P_dist_squared == 0] = 1\n",
    "        K = torch.mul(P_dist_squared, torch.log(P_dist_squared))\n",
    "        # construct matrix L\n",
    "        O = torch.FloatTensor(N, 1).fill_(1)\n",
    "        Z = torch.FloatTensor(3, 3).fill_(0)\n",
    "        P = torch.cat((O, X, Y), 1)\n",
    "        L = torch.cat((torch.cat((K, P), 1), torch.cat(\n",
    "            (P.transpose(0, 1), Z), 1)), 0)\n",
    "        Li = torch.inverse(L)\n",
    "        if self.use_cuda:\n",
    "            Li = Li.cuda()\n",
    "        return Li\n",
    "\n",
    "    def apply_transformation(self, theta, points):\n",
    "        if theta.dim() == 2:\n",
    "            theta = theta.unsqueeze(2).unsqueeze(3)\n",
    "        # points should be in the [B,H,W,2] format,\n",
    "        # where points[:,:,:,0] are the X coords\n",
    "        # and points[:,:,:,1] are the Y coords\n",
    "\n",
    "        # input are the corresponding control points P_i\n",
    "        batch_size = theta.size()[0]\n",
    "        # split theta into point coordinates\n",
    "        Q_X = theta[:, :self.N, :, :].squeeze(3)\n",
    "        Q_Y = theta[:, self.N:, :, :].squeeze(3)\n",
    "        Q_X = Q_X + self.P_X_base.expand_as(Q_X)\n",
    "        Q_Y = Q_Y + self.P_Y_base.expand_as(Q_Y)\n",
    "\n",
    "        # get spatial dimensions of points\n",
    "        points_b = points.size()[0]\n",
    "        points_h = points.size()[1]\n",
    "        points_w = points.size()[2]\n",
    "\n",
    "        # repeat pre-defined control points along spatial dimensions of points to be transformed\n",
    "        P_X = self.P_X.expand((1, points_h, points_w, 1, self.N))\n",
    "        P_Y = self.P_Y.expand((1, points_h, points_w, 1, self.N))\n",
    "\n",
    "        # compute weigths for non-linear part\n",
    "        W_X = torch.bmm(self.Li[:, :self.N, :self.N].expand(\n",
    "            (batch_size, self.N, self.N)), Q_X)\n",
    "        W_Y = torch.bmm(self.Li[:, :self.N, :self.N].expand(\n",
    "            (batch_size, self.N, self.N)), Q_Y)\n",
    "        # reshape\n",
    "        # W_X,W,Y: size [B,H,W,1,N]\n",
    "        W_X = W_X.unsqueeze(3).unsqueeze(4).transpose(\n",
    "            1, 4).repeat(1, points_h, points_w, 1, 1)\n",
    "        W_Y = W_Y.unsqueeze(3).unsqueeze(4).transpose(\n",
    "            1, 4).repeat(1, points_h, points_w, 1, 1)\n",
    "        # compute weights for affine part\n",
    "        A_X = torch.bmm(self.Li[:, self.N:, :self.N].expand(\n",
    "            (batch_size, 3, self.N)), Q_X)\n",
    "        A_Y = torch.bmm(self.Li[:, self.N:, :self.N].expand(\n",
    "            (batch_size, 3, self.N)), Q_Y)\n",
    "        # reshape\n",
    "        # A_X,A,Y: size [B,H,W,1,3]\n",
    "        A_X = A_X.unsqueeze(3).unsqueeze(4).transpose(\n",
    "            1, 4).repeat(1, points_h, points_w, 1, 1)\n",
    "        A_Y = A_Y.unsqueeze(3).unsqueeze(4).transpose(\n",
    "            1, 4).repeat(1, points_h, points_w, 1, 1)\n",
    "\n",
    "        # compute distance P_i - (grid_X,grid_Y)\n",
    "        # grid is expanded in point dim 4, but not in batch dim 0, as points P_X,P_Y are fixed for all batch\n",
    "        points_X_for_summation = points[:, :, :, 0].unsqueeze(\n",
    "            3).unsqueeze(4).expand(points[:, :, :, 0].size()+(1, self.N))\n",
    "        points_Y_for_summation = points[:, :, :, 1].unsqueeze(\n",
    "            3).unsqueeze(4).expand(points[:, :, :, 1].size()+(1, self.N))\n",
    "\n",
    "        if points_b == 1:\n",
    "            delta_X = points_X_for_summation-P_X\n",
    "            delta_Y = points_Y_for_summation-P_Y\n",
    "        else:\n",
    "            # use expanded P_X,P_Y in batch dimension\n",
    "            delta_X = points_X_for_summation - \\\n",
    "                P_X.expand_as(points_X_for_summation)\n",
    "            delta_Y = points_Y_for_summation - \\\n",
    "                P_Y.expand_as(points_Y_for_summation)\n",
    "\n",
    "        dist_squared = torch.pow(delta_X, 2)+torch.pow(delta_Y, 2)\n",
    "        # U: size [1,H,W,1,N]\n",
    "        dist_squared[dist_squared == 0] = 1  # avoid NaN in log computation\n",
    "        U = torch.mul(dist_squared, torch.log(dist_squared))\n",
    "\n",
    "        # expand grid in batch dimension if necessary\n",
    "        points_X_batch = points[:, :, :, 0].unsqueeze(3)\n",
    "        points_Y_batch = points[:, :, :, 1].unsqueeze(3)\n",
    "        if points_b == 1:\n",
    "            points_X_batch = points_X_batch.expand(\n",
    "                (batch_size,)+points_X_batch.size()[1:])\n",
    "            points_Y_batch = points_Y_batch.expand(\n",
    "                (batch_size,)+points_Y_batch.size()[1:])\n",
    "\n",
    "        points_X_prime = A_X[:, :, :, :, 0] + \\\n",
    "            torch.mul(A_X[:, :, :, :, 1], points_X_batch) + \\\n",
    "            torch.mul(A_X[:, :, :, :, 2], points_Y_batch) + \\\n",
    "            torch.sum(torch.mul(W_X, U.expand_as(W_X)), 4)\n",
    "\n",
    "        points_Y_prime = A_Y[:, :, :, :, 0] + \\\n",
    "            torch.mul(A_Y[:, :, :, :, 1], points_X_batch) + \\\n",
    "            torch.mul(A_Y[:, :, :, :, 2], points_Y_batch) + \\\n",
    "            torch.sum(torch.mul(W_Y, U.expand_as(W_Y)), 4)\n",
    "\n",
    "        return torch.cat((points_X_prime, points_Y_prime), 3)\n",
    "\n",
    "# Defines the Unet generator.\n",
    "# |num_downs|: number of downsamplings in UNet. For example,\n",
    "# if |num_downs| == 7, image of size 128x128 will become of size 1x1\n",
    "# at the bottleneck\n",
    "\n",
    "\n",
    "class UnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
    "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(\n",
    "            ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
    "        for i in range(num_downs - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(\n",
    "                ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
    "        unet_block = UnetSkipConnectionBlock(\n",
    "            ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(\n",
    "            ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(\n",
    "            ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
    "        unet_block = UnetSkipConnectionBlock(\n",
    "            output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
    "\n",
    "        self.model = unet_block\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "# Defines the submodule with skip connection.\n",
    "# X -------------------identity---------------------- X\n",
    "#   |-- downsampling -- |submodule| -- upsampling --|\n",
    "class UnetSkipConnectionBlock(nn.Module):\n",
    "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
    "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        if input_nc is None:\n",
    "            input_nc = outer_nc\n",
    "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=use_bias)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = norm_layer(inner_nc)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = norm_layer(outer_nc)\n",
    "\n",
    "        if outermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            upconv = nn.Conv2d(inner_nc * 2, outer_nc,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=use_bias)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upsample, upconv, upnorm]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            upconv = nn.Conv2d(inner_nc, outer_nc, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upsample, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            upconv = nn.Conv2d(inner_nc*2, outer_nc, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=use_bias)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upsample, upconv, upnorm]\n",
    "\n",
    "            if use_dropout:\n",
    "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
    "            else:\n",
    "                model = down + [submodule] + up\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "\n",
    "class Vgg19(nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(2, 7):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(7, 12):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 21):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(21, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_relu1 = self.slice1(X)\n",
    "        h_relu2 = self.slice2(h_relu1)\n",
    "        h_relu3 = self.slice3(h_relu2)\n",
    "        h_relu4 = self.slice4(h_relu3)\n",
    "        h_relu5 = self.slice5(h_relu4)\n",
    "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
    "        return out\n",
    "\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, layids=None):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        self.vgg = Vgg19()\n",
    "        self.vgg.cuda()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]\n",
    "        self.layids = layids\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "        loss = 0\n",
    "        if self.layids is None:\n",
    "            self.layids = list(range(len(x_vgg)))\n",
    "        for i in self.layids:\n",
    "            loss += self.weights[i] * \\\n",
    "                self.criterion(x_vgg[i], y_vgg[i].detach())\n",
    "        return loss\n",
    "\n",
    "\n",
    "class DT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DT, self).__init__()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        dt = torch.abs(x1 - x2)\n",
    "        return dt\n",
    "\n",
    "\n",
    "class DT2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DT, self).__init__()\n",
    "\n",
    "    def forward(self, x1, y1, x2, y2):\n",
    "        dt = torch.sqrt(torch.mul(x1 - x2, x1 - x2) +\n",
    "                        torch.mul(y1 - y2, y1 - y2))\n",
    "        return dt\n",
    "\n",
    "\n",
    "class GicLoss(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(GicLoss, self).__init__()\n",
    "        self.dT = DT()\n",
    "        self.opt = opt\n",
    "\n",
    "    def forward(self, grid):\n",
    "        Gx = grid[:, :, :, 0]\n",
    "        Gy = grid[:, :, :, 1]\n",
    "        Gxcenter = Gx[:, 1:self.opt.fine_height - 1, 1:self.opt.fine_width - 1]\n",
    "        Gxup = Gx[:, 0:self.opt.fine_height - 2, 1:self.opt.fine_width - 1]\n",
    "        Gxdown = Gx[:, 2:self.opt.fine_height, 1:self.opt.fine_width - 1]\n",
    "        Gxleft = Gx[:, 1:self.opt.fine_height - 1, 0:self.opt.fine_width - 2]\n",
    "        Gxright = Gx[:, 1:self.opt.fine_height - 1, 2:self.opt.fine_width]\n",
    "\n",
    "        Gycenter = Gy[:, 1:self.opt.fine_height - 1, 1:self.opt.fine_width - 1]\n",
    "        Gyup = Gy[:, 0:self.opt.fine_height - 2, 1:self.opt.fine_width - 1]\n",
    "        Gydown = Gy[:, 2:self.opt.fine_height, 1:self.opt.fine_width - 1]\n",
    "        Gyleft = Gy[:, 1:self.opt.fine_height - 1, 0:self.opt.fine_width - 2]\n",
    "        Gyright = Gy[:, 1:self.opt.fine_height - 1, 2:self.opt.fine_width]\n",
    "\n",
    "        dtleft = self.dT(Gxleft, Gxcenter)\n",
    "        dtright = self.dT(Gxright, Gxcenter)\n",
    "        dtup = self.dT(Gyup, Gycenter)\n",
    "        dtdown = self.dT(Gydown, Gycenter)\n",
    "\n",
    "        return torch.sum(torch.abs(dtleft - dtright) + torch.abs(dtup - dtdown))\n",
    "\n",
    "\n",
    "class GMM(nn.Module):\n",
    "    \"\"\" Geometric Matching Module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        super(GMM, self).__init__()\n",
    "        self.extractionA = FeatureExtraction(\n",
    "            22, ngf=64, n_layers=3, norm_layer=nn.BatchNorm2d)\n",
    "        self.extractionB = FeatureExtraction(\n",
    "            1, ngf=64, n_layers=3, norm_layer=nn.BatchNorm2d)\n",
    "        self.l2norm = FeatureL2Norm()\n",
    "        self.correlation = FeatureCorrelation()\n",
    "        self.regression = FeatureRegression(\n",
    "            input_nc=192, output_dim=2*opt.grid_size**2, use_cuda=True)\n",
    "        self.gridGen = TpsGridGen(\n",
    "            opt.fine_height, opt.fine_width, use_cuda=True, grid_size=opt.grid_size)\n",
    "\n",
    "    def forward(self, inputA, inputB):\n",
    "        featureA = self.extractionA(inputA)\n",
    "        featureB = self.extractionB(inputB)\n",
    "        featureA = self.l2norm(featureA)\n",
    "        featureB = self.l2norm(featureB)\n",
    "        correlation = self.correlation(featureA, featureB)\n",
    "\n",
    "        theta = self.regression(correlation)\n",
    "        grid = self.gridGen(theta)\n",
    "        return grid, theta\n",
    "\n",
    "\n",
    "def save_checkpoint(model, save_path):\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "    torch.save(model.cpu().state_dict(), save_path)\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        return\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # train.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from cp_dataset import CPDataset, CPDataLoader\n",
    "from networks import GicLoss, GMM, UnetGenerator, VGGLoss, load_checkpoint, save_checkpoint\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from visualization import board_add_image, board_add_images\n",
    "\n",
    "\n",
    "def get_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--name\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--name\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"\")\n",
    "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=4)\n",
    "\n",
    "    parser.add_argument(\"--dataroot\", default=\"data\")\n",
    "\n",
    "    parser.add_argument(\"--datamode\", default=\"train\")\n",
    "\n",
    "    parser.add_argument(\"--stage\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--stage\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--data_list\", default=\"train_pairs.txt\")\n",
    "\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "    parser.add_argument(\"--radius\", type=int, default=5)\n",
    "    parser.add_argument(\"--grid_size\", type=int, default=5)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001,\n",
    "                        help='initial learning rate for adam')\n",
    "    parser.add_argument('--tensorboard_dir', type=str,\n",
    "                        default='tensorboard', help='save tensorboard infos')\n",
    "    parser.add_argument('--checkpoint_dir', type=str,\n",
    "                        default='checkpoints', help='save checkpoint infos')\n",
    "    parser.add_argument('--checkpoint', type=str, default='',\n",
    "                        help='model checkpoint for initialization')\n",
    "    parser.add_argument(\"--display_count\", type=int, default=20)\n",
    "    parser.add_argument(\"--save_count\", type=int, default=5000)\n",
    "    parser.add_argument(\"--keep_step\", type=int, default=100000)\n",
    "    parser.add_argument(\"--decay_step\", type=int, default=100000)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true',\n",
    "                        help='shuffle input data')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "\n",
    "def train_gmm(opt, train_loader, model, board):\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    # criterion\n",
    "    criterionL1 = nn.L1Loss()\n",
    "    gicloss = GicLoss(opt)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step: 1.0 -\n",
    "                                                  max(0, step - opt.keep_step) / float(opt.decay_step + 1))\n",
    "\n",
    "    for step in range(opt.keep_step + opt.decay_step):\n",
    "        iter_start_time = time.time()\n",
    "        inputs = train_loader.next_batch()\n",
    "\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image'].cuda()\n",
    "        im_h = inputs['head'].cuda()\n",
    "        shape = inputs['shape'].cuda()\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "        im_c = inputs['parse_cloth'].cuda()\n",
    "        im_g = inputs['grid_image'].cuda()\n",
    "\n",
    "        grid, theta = model(agnostic, cm)    # can be added c too for new training\n",
    "        warped_cloth = F.grid_sample(c, grid, padding_mode='border')\n",
    "        warped_mask = F.grid_sample(cm, grid, padding_mode='zeros')\n",
    "        warped_grid = F.grid_sample(im_g, grid, padding_mode='zeros')\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                   [c, warped_cloth, im_c],\n",
    "                   [warped_grid, (warped_cloth+im)*0.5, im]]\n",
    "\n",
    "        Lwarp = criterionL1(warped_cloth, im_c)    # loss for warped cloth\n",
    "\n",
    "        # grid regularization loss\n",
    "        Lgic = gicloss(grid)\n",
    "        # 200x200 = 40.000 * 0.001\n",
    "        Lgic = Lgic / (grid.shape[0] * grid.shape[1] * grid.shape[2])\n",
    "\n",
    "        loss = Lwarp + 40 * Lgic    # total GMM loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            board_add_images(board, 'combine', visuals, step+1)\n",
    "            board.add_scalar('loss', loss.item(), step+1)\n",
    "            board.add_scalar('40*Lgic', (40*Lgic).item(), step+1)\n",
    "            board.add_scalar('Lwarp', Lwarp.item(), step+1)\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f, loss: %4f, (40*Lgic): %.8f, Lwarp: %.6f' %\n",
    "                  (step+1, t, loss.item(), (40*Lgic).item(), Lwarp.item()), flush=True)\n",
    "\n",
    "        if (step+1) % opt.save_count == 0:\n",
    "            save_checkpoint(model, os.path.join(\n",
    "                opt.checkpoint_dir, opt.name, 'step_%06d.pth' % (step+1)))\n",
    "\n",
    "\n",
    "def train_tom(opt, train_loader, model, board):\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    # criterion\n",
    "    criterionL1 = nn.L1Loss()\n",
    "    criterionVGG = VGGLoss()\n",
    "    criterionMask = nn.L1Loss()\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step: 1.0 -\n",
    "                                                  max(0, step - opt.keep_step) / float(opt.decay_step + 1))\n",
    "\n",
    "    for step in range(opt.keep_step + opt.decay_step):\n",
    "        iter_start_time = time.time()\n",
    "        inputs = train_loader.next_batch()\n",
    "\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image']\n",
    "        im_h = inputs['head']\n",
    "        shape = inputs['shape']\n",
    "\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "        pcm = inputs['parse_cloth_mask'].cuda()\n",
    "\n",
    "        # outputs = model(torch.cat([agnostic, c], 1))  # CP-VTON\n",
    "        outputs = model(torch.cat([agnostic, c, cm], 1))  # CP-VTON+\n",
    "        p_rendered, m_composite = torch.split(outputs, 3, 1)\n",
    "        p_rendered = F.tanh(p_rendered)\n",
    "        m_composite = F.sigmoid(m_composite)\n",
    "        p_tryon = c * m_composite + p_rendered * (1 - m_composite)\n",
    "\n",
    "        \"\"\"visuals = [[im_h, shape, im_pose],\n",
    "                   [c, cm*2-1, m_composite*2-1],\n",
    "                   [p_rendered, p_tryon, im]]\"\"\"  # CP-VTON\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                   [c, pcm*2-1, m_composite*2-1],\n",
    "                   [p_rendered, p_tryon, im]]  # CP-VTON+\n",
    "\n",
    "        loss_l1 = criterionL1(p_tryon, im)\n",
    "        loss_vgg = criterionVGG(p_tryon, im)\n",
    "        # loss_mask = criterionMask(m_composite, cm)  # CP-VTON\n",
    "        loss_mask = criterionMask(m_composite, pcm)  # CP-VTON+\n",
    "        loss = loss_l1 + loss_vgg + loss_mask\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            board_add_images(board, 'combine', visuals, step+1)\n",
    "            board.add_scalar('metric', loss.item(), step+1)\n",
    "            board.add_scalar('L1', loss_l1.item(), step+1)\n",
    "            board.add_scalar('VGG', loss_vgg.item(), step+1)\n",
    "            board.add_scalar('MaskL1', loss_mask.item(), step+1)\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f, loss: %.4f, l1: %.4f, vgg: %.4f, mask: %.4f'\n",
    "                  % (step+1, t, loss.item(), loss_l1.item(),\n",
    "                     loss_vgg.item(), loss_mask.item()), flush=True)\n",
    "\n",
    "        if (step+1) % opt.save_count == 0:\n",
    "            save_checkpoint(model, os.path.join(\n",
    "                opt.checkpoint_dir, opt.name, 'step_%06d.pth' % (step+1)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    opt = get_opt()\n",
    "    print(opt)\n",
    "    print(\"Start to train stage: %s, named: %s!\" % (opt.stage, opt.name))\n",
    "\n",
    "    # create dataset\n",
    "    train_dataset = CPDataset(opt)\n",
    "\n",
    "    # create dataloader\n",
    "    train_loader = CPDataLoader(opt, train_dataset)\n",
    "\n",
    "    # visualization\n",
    "    if not os.path.exists(opt.tensorboard_dir):\n",
    "        os.makedirs(opt.tensorboard_dir)\n",
    "    board = SummaryWriter(logdir=os.path.join(opt.tensorboard_dir, opt.name))\n",
    "\n",
    "    # create model & train & save the final checkpoint\n",
    "    if opt.stage == 'GMM':\n",
    "        model = GMM(opt)\n",
    "        if not opt.checkpoint == '' and os.path.exists(opt.checkpoint):\n",
    "            load_checkpoint(model, opt.checkpoint)\n",
    "        train_gmm(opt, train_loader, model, board)\n",
    "        save_checkpoint(model, os.path.join(\n",
    "            opt.checkpoint_dir, opt.name, 'gmm_final.pth'))\n",
    "    elif opt.stage == 'TOM':\n",
    "        # model = UnetGenerator(25, 4, 6, ngf=64, norm_layer=nn.InstanceNorm2d)  # CP-VTON\n",
    "        model = UnetGenerator(\n",
    "            26, 4, 6, ngf=64, norm_layer=nn.InstanceNorm2d)  # CP-VTON+\n",
    "        if not opt.checkpoint == '' and os.path.exists(opt.checkpoint):\n",
    "            load_checkpoint(model, opt.checkpoint)\n",
    "        train_tom(opt, train_loader, model, board)\n",
    "        save_checkpoint(model, os.path.join(\n",
    "            opt.checkpoint_dir, opt.name, 'tom_final.pth'))\n",
    "    else:\n",
    "        raise NotImplementedError('Model [%s] is not implemented' % opt.stage)\n",
    "\n",
    "    print('Finished training %s, named: %s!' % (opt.stage, opt.name))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from cp_dataset import CPDataset, CPDataLoader\n",
    "from networks import GMM, UnetGenerator, load_checkpoint\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from visualization import board_add_image, board_add_images, save_images\n",
    "\n",
    "\n",
    "def get_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--name\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--name\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"\")\n",
    "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=4)\n",
    "\n",
    "    parser.add_argument(\"--dataroot\", default=\"data\")\n",
    "\n",
    "    # parser.add_argument(\"--datamode\", default=\"train\")\n",
    "    parser.add_argument(\"--datamode\", default=\"test\")\n",
    "\n",
    "    parser.add_argument(\"--stage\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--stage\", default=\"TOM\")\n",
    "\n",
    "    # parser.add_argument(\"--data_list\", default=\"train_pairs.txt\")\n",
    "    parser.add_argument(\"--data_list\", default=\"test_pairs.txt\")\n",
    "\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "    parser.add_argument(\"--radius\", type=int, default=5)\n",
    "    parser.add_argument(\"--grid_size\", type=int, default=5)\n",
    "\n",
    "    parser.add_argument('--tensorboard_dir', type=str,\n",
    "                        default='tensorboard', help='save tensorboard infos')\n",
    "\n",
    "    parser.add_argument('--result_dir', type=str,\n",
    "                        default='result', help='save result infos')\n",
    "\n",
    "    parser.add_argument('--checkpoint', type=str, default='checkpoints/GMM/gmm_final.pth', help='model checkpoint for test')\n",
    "    # parser.add_argument('--checkpoint', type=str, default='checkpoints/TOM/tom_final.pth', help='model checkpoint for test')\n",
    "\n",
    "    parser.add_argument(\"--display_count\", type=int, default=1)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true',\n",
    "                        help='shuffle input data')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "\n",
    "def test_gmm(opt, test_loader, model, board):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    base_name = os.path.basename(opt.checkpoint)\n",
    "    name = opt.name\n",
    "    save_dir = os.path.join(opt.result_dir, name, opt.datamode)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    warp_cloth_dir = os.path.join(save_dir, 'warp-cloth')\n",
    "    if not os.path.exists(warp_cloth_dir):\n",
    "        os.makedirs(warp_cloth_dir)\n",
    "    warp_mask_dir = os.path.join(save_dir, 'warp-mask')\n",
    "    if not os.path.exists(warp_mask_dir):\n",
    "        os.makedirs(warp_mask_dir)\n",
    "    result_dir1 = os.path.join(save_dir, 'result_dir')\n",
    "    if not os.path.exists(result_dir1):\n",
    "        os.makedirs(result_dir1)\n",
    "    overlayed_TPS_dir = os.path.join(save_dir, 'overlayed_TPS')\n",
    "    if not os.path.exists(overlayed_TPS_dir):\n",
    "        os.makedirs(overlayed_TPS_dir)\n",
    "    warped_grid_dir = os.path.join(save_dir, 'warped_grid')\n",
    "    if not os.path.exists(warped_grid_dir):\n",
    "        os.makedirs(warped_grid_dir)\n",
    "    for step, inputs in enumerate(test_loader.data_loader):\n",
    "        iter_start_time = time.time()\n",
    "\n",
    "        c_names = inputs['c_name']\n",
    "        im_names = inputs['im_name']\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image'].cuda()\n",
    "        im_h = inputs['head'].cuda()\n",
    "        shape = inputs['shape'].cuda()\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "        im_c = inputs['parse_cloth'].cuda()\n",
    "        im_g = inputs['grid_image'].cuda()\n",
    "        shape_ori = inputs['shape_ori']  # original body shape without blurring\n",
    "\n",
    "        grid, theta = model(agnostic, cm)\n",
    "        warped_cloth = F.grid_sample(c, grid, padding_mode='border')\n",
    "        warped_mask = F.grid_sample(cm, grid, padding_mode='zeros')\n",
    "        warped_grid = F.grid_sample(im_g, grid, padding_mode='zeros')\n",
    "        overlay = 0.7 * warped_cloth + 0.3 * im\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                   [c, warped_cloth, im_c],\n",
    "                   [warped_grid, (warped_cloth+im)*0.5, im]]\n",
    "\n",
    "        # save_images(warped_cloth, c_names, warp_cloth_dir)\n",
    "        # save_images(warped_mask*2-1, c_names, warp_mask_dir)\n",
    "        save_images(warped_cloth, im_names, warp_cloth_dir)\n",
    "        save_images(warped_mask * 2 - 1, im_names, warp_mask_dir)\n",
    "        save_images(shape_ori.cuda() * 0.2 + warped_cloth *\n",
    "                    0.8, im_names, result_dir1)\n",
    "        save_images(warped_grid, im_names, warped_grid_dir)\n",
    "        save_images(overlay, im_names, overlayed_TPS_dir)\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            board_add_images(board, 'combine', visuals, step+1)\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f' % (step+1, t), flush=True)\n",
    "\n",
    "\n",
    "def test_tom(opt, test_loader, model, board):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    base_name = os.path.basename(opt.checkpoint)\n",
    "    # save_dir = os.path.join(opt.result_dir, base_name, opt.datamode)\n",
    "    save_dir = os.path.join(opt.result_dir, opt.name, opt.datamode)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    try_on_dir = os.path.join(save_dir, 'try-on')\n",
    "    if not os.path.exists(try_on_dir):\n",
    "        os.makedirs(try_on_dir)\n",
    "    p_rendered_dir = os.path.join(save_dir, 'p_rendered')\n",
    "    if not os.path.exists(p_rendered_dir):\n",
    "        os.makedirs(p_rendered_dir)\n",
    "    m_composite_dir = os.path.join(save_dir, 'm_composite')\n",
    "    if not os.path.exists(m_composite_dir):\n",
    "        os.makedirs(m_composite_dir)\n",
    "    im_pose_dir = os.path.join(save_dir, 'im_pose')\n",
    "    if not os.path.exists(im_pose_dir):\n",
    "        os.makedirs(im_pose_dir)\n",
    "    shape_dir = os.path.join(save_dir, 'shape')\n",
    "    if not os.path.exists(shape_dir):\n",
    "        os.makedirs(shape_dir)\n",
    "    im_h_dir = os.path.join(save_dir, 'im_h')\n",
    "    if not os.path.exists(im_h_dir):\n",
    "        os.makedirs(im_h_dir)  # for test data\n",
    "\n",
    "    print('Dataset size: %05d!' % (len(test_loader.dataset)), flush=True)\n",
    "    for step, inputs in enumerate(test_loader.data_loader):\n",
    "        iter_start_time = time.time()\n",
    "\n",
    "        im_names = inputs['im_name']\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image']\n",
    "        im_h = inputs['head']\n",
    "        shape = inputs['shape']\n",
    "\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "\n",
    "        # outputs = model(torch.cat([agnostic, c], 1))  # CP-VTON\n",
    "        outputs = model(torch.cat([agnostic, c, cm], 1))  # CP-VTON+\n",
    "        p_rendered, m_composite = torch.split(outputs, 3, 1)\n",
    "        p_rendered = F.tanh(p_rendered)\n",
    "        m_composite = F.sigmoid(m_composite)\n",
    "        p_tryon = c * m_composite + p_rendered * (1 - m_composite)\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                   [c, 2*cm-1, m_composite],\n",
    "                   [p_rendered, p_tryon, im]]\n",
    "\n",
    "        save_images(p_tryon, im_names, try_on_dir)\n",
    "        save_images(im_h, im_names, im_h_dir)\n",
    "        save_images(shape, im_names, shape_dir)\n",
    "        save_images(im_pose, im_names, im_pose_dir)\n",
    "        save_images(m_composite, im_names, m_composite_dir)\n",
    "        save_images(p_rendered, im_names, p_rendered_dir)  # For test data\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            board_add_images(board, 'combine', visuals, step+1)\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f' % (step+1, t), flush=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    opt = get_opt()\n",
    "    print(opt)\n",
    "    print(\"Start to test stage: %s, named: %s!\" % (opt.stage, opt.name))\n",
    "\n",
    "    # create dataset\n",
    "    test_dataset = CPDataset(opt)\n",
    "\n",
    "    # create dataloader\n",
    "    test_loader = CPDataLoader(opt, test_dataset)\n",
    "\n",
    "    # visualization\n",
    "    if not os.path.exists(opt.tensorboard_dir):\n",
    "        os.makedirs(opt.tensorboard_dir)\n",
    "    board = SummaryWriter(logdir=os.path.join(opt.tensorboard_dir, opt.name))\n",
    "\n",
    "    # create model & test\n",
    "    if opt.stage == 'GMM':\n",
    "        model = GMM(opt)\n",
    "        load_checkpoint(model, opt.checkpoint)\n",
    "        with torch.no_grad():\n",
    "            test_gmm(opt, test_loader, model, board)\n",
    "    elif opt.stage == 'TOM':\n",
    "        # model = UnetGenerator(25, 4, 6, ngf=64, norm_layer=nn.InstanceNorm2d)  # CP-VTON\n",
    "        model = UnetGenerator(26, 4, 6, ngf=64, norm_layer=nn.InstanceNorm2d)  # CP-VTON+\n",
    "        load_checkpoint(model, opt.checkpoint)\n",
    "        with torch.no_grad():\n",
    "            test_tom(opt, test_loader, model, board)\n",
    "    else:\n",
    "        raise NotImplementedError('Model [%s] is not implemented' % opt.stage)\n",
    "\n",
    "    print('Finished test %s, named: %s!' % (opt.stage, opt.name))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # visualization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "def tensor_for_board(img_tensor):\n",
    "    # map into [0,1]\n",
    "    tensor = (img_tensor.clone()+1) * 0.5\n",
    "    tensor.cpu().clamp(0, 1)\n",
    "\n",
    "    if tensor.size(1) == 1:\n",
    "        tensor = tensor.repeat(1, 3, 1, 1)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_list_for_board(img_tensors_list):\n",
    "    grid_h = len(img_tensors_list)\n",
    "    grid_w = max(len(img_tensors) for img_tensors in img_tensors_list)\n",
    "\n",
    "    batch_size, channel, height, width = tensor_for_board(\n",
    "        img_tensors_list[0][0]).size()\n",
    "    canvas_h = grid_h * height\n",
    "    canvas_w = grid_w * width\n",
    "    canvas = torch.FloatTensor(\n",
    "        batch_size, channel, canvas_h, canvas_w).fill_(0.5)\n",
    "    for i, img_tensors in enumerate(img_tensors_list):\n",
    "        for j, img_tensor in enumerate(img_tensors):\n",
    "            offset_h = i * height\n",
    "            offset_w = j * width\n",
    "            tensor = tensor_for_board(img_tensor)\n",
    "            canvas[:, :, offset_h: offset_h + height,\n",
    "                   offset_w: offset_w + width].copy_(tensor)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def board_add_image(board, tag_name, img_tensor, step_count):\n",
    "    tensor = tensor_for_board(img_tensor)\n",
    "\n",
    "    for i, img in enumerate(tensor):\n",
    "        board.add_image('%s/%03d' % (tag_name, i), img, step_count)\n",
    "\n",
    "\n",
    "def board_add_images(board, tag_name, img_tensors_list, step_count):\n",
    "    tensor = tensor_list_for_board(img_tensors_list)\n",
    "\n",
    "    for i, img in enumerate(tensor):\n",
    "        board.add_image('%s/%03d' % (tag_name, i), img, step_count)\n",
    "\n",
    "\n",
    "def save_images(img_tensors, img_names, save_dir):\n",
    "    for img_tensor, img_name in zip(img_tensors, img_names):\n",
    "        tensor = (img_tensor.clone()+1)*0.5 * 255\n",
    "        tensor = tensor.cpu().clamp(0, 255)\n",
    "\n",
    "        array = tensor.numpy().astype('uint8')\n",
    "        if array.shape[0] == 1:\n",
    "            array = array.squeeze(0)\n",
    "        elif array.shape[0] == 3:\n",
    "            array = array.swapaxes(0, 1).swapaxes(1, 2)\n",
    "\n",
    "        Image.fromarray(array).save(os.path.join(save_dir, img_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
